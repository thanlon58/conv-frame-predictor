{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "import PIL\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code takes jpg's, preps them for the model, and writes them to a tfrecord\n",
    "## I've spent a bunch of time working with code like this lately so I really don't want to document it rn. Here's a very very brief rundown:\n",
    "\n",
    "<ul>\n",
    "    <li>TFRecords are desirable for a few reasons. They're supposed to be fast, and they let you use massive datasets w/o loading them into memory all at once</li>\n",
    "    <li>The catch is that they can be a pain to use. This is because they only accept limited datatypes (integers, floats, strings, and bytes). You'll notice that arrays are not listed as data that these records can hold.</li>\n",
    "    <li>So, first you need to turn your numpy arrays into binary strings, then write those strings to the tfrecord. In hindsight it really isn't a huge pain, there's just a bunch of weird TF functions you need to work with and the documentation isn't super general.</li>\n",
    "    <li>https://tensorflow.google.cn/tutorials/load_data/tfrecord?hl=en</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "    \n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "X Filenames Length:  2001\n",
      "Y Filenames Length:  2001\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = [512, 512]\n",
    "\n",
    "x_dir = '/home/tom/data/frames/both/x'\n",
    "y_dir = '/home/tom/data/frames/both/y'\n",
    "\n",
    "x_filenames = glob.glob(x_dir+'/*')\n",
    "x_filenames.sort()\n",
    "y_filenames = glob.glob(y_dir+'/*')\n",
    "y_filenames.sort()\n",
    "\n",
    "\n",
    "print(\"-\"*20)\n",
    "print(\"X Filenames Length: \", len(x_filenames))\n",
    "print(\"Y Filenames Length: \", len(y_filenames))\n",
    "print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hold\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n",
      "(512, 512, 15)\n"
     ]
    }
   ],
   "source": [
    "# Create tfrecord:\n",
    "outs = '/home/tom/data/road_1frame_predictor/stacked_roadframes.tfrecord'\n",
    "with tf.io.TFRecordWriter(outs) as writer:\n",
    "    # I'm just using 140 datapoints here\n",
    "    # My model is overfit and I don't care\n",
    "    for index in range(150-10):\n",
    "        i = index + 5\n",
    "        x = np.zeros((512,512,3*5))\n",
    "        for j in range(5):\n",
    "            if index == 0:\n",
    "                Image.open(x_filenames[i-j]).show()\n",
    "            x[:,:,3*j:3*(j+1)] = np.array(Image.open(x_filenames[i-j]).resize((512,512)).convert(\"RGB\"))\n",
    "        \n",
    "        y = Image.open(y_filenames[i]).resize((512,512)).convert(\"RGB\")\n",
    "\n",
    "        x_array = x/255\n",
    "        y_array = np.array(y)/255\n",
    "        \n",
    "        \n",
    "        x_array = x_array.astype('float64')\n",
    "        y_array = y_array.astype('float64')\n",
    "\n",
    "        x_string = (x_array).tostring()\n",
    "        y_string = (y_array).tostring()\n",
    "\n",
    "        x_bytes = tf.compat.as_bytes(x_string)\n",
    "        y_bytes = tf.compat.as_bytes(y_string)\n",
    "\n",
    "        x_feature = _bytes_feature(x_bytes)\n",
    "        y_feature = _bytes_feature(y_bytes)\n",
    "\n",
    "        feature = {\n",
    "            'image':x_feature,\n",
    "            'label':y_feature\n",
    "        }\n",
    "\n",
    "        feat = tf.train.Features(feature=feature)\n",
    "        example = tf.train.Example(features=feat)\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The rest of this code just verifies that the images were written correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"DecodeRaw:0\", shape=(None,), dtype=float64)\n",
      "Tensor(\"Reshape:0\", shape=(512, 512, 15), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Read tfrecord\n",
    "\n",
    "def _parse_function(proto):\n",
    "    keys_to_features = {\n",
    "        'image':tf.io.FixedLenFeature([], tf.string),\n",
    "        'label':tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    \n",
    "    parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n",
    "    \n",
    "    parsed_features['image'] = tf.io.decode_raw(parsed_features['image'], tf.float64)\n",
    "    parsed_features['label'] = tf.io.decode_raw(parsed_features['label'], tf.float64)\n",
    "    \n",
    "    print(parsed_features['image'])\n",
    "    \n",
    "    parsed_features['image'] = tf.reshape(parsed_features['image'], [512,512,15])\n",
    "    parsed_features['label'] = tf.reshape(parsed_features['label'], [512,512,3])\n",
    "    \n",
    "    print(parsed_features['image'])\n",
    "    \n",
    "    return parsed_features['image'], parsed_features['label']\n",
    "\n",
    "def load_dataset(path):\n",
    "    dataset = tf.data.TFRecordDataset(path)\n",
    "    \n",
    "    dataset = dataset.map(_parse_function, 1)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def get_dataset(path):\n",
    "    dataset = load_dataset(path)\n",
    "    \n",
    "    dataset = dataset.shuffle(100)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(10)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "ds = get_dataset('/home/tom/data/road_1frame_predictor/stacked_roadframes.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbatch, ybatch = next(iter(ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512, 15)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n",
      "(512, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "x = xbatch[1]\n",
    "y = ybatch[1]\n",
    "\n",
    "print(x.shape)\n",
    "firstframe = x[:,:,:3]\n",
    "lastframe = x[:,:,12:]\n",
    "print(firstframe.shape)\n",
    "print(lastframe.shape)\n",
    "print(y.shape)\n",
    "\n",
    "Image.fromarray((firstframe.numpy()*255).astype('uint8')).show()\n",
    "Image.fromarray((lastframe.numpy()*255).astype('uint8')).show()\n",
    "Image.fromarray((y.numpy()*255).astype('uint8')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
